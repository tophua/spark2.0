17/09/19 08:28:17.029 main INFO SparkContext: Running Spark version 2.3.0-SNAPSHOT
17/09/19 08:28:21.600 main WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/19 08:28:23.334 main INFO SparkContext: Submitted application: test
17/09/19 08:28:23.747 main INFO SecurityManager: Changing view acls to: liush
17/09/19 08:28:23.748 main INFO SecurityManager: Changing modify acls to: liush
17/09/19 08:28:23.749 main INFO SecurityManager: Changing view acls groups to: 
17/09/19 08:28:23.750 main INFO SecurityManager: Changing modify acls groups to: 
17/09/19 08:28:23.751 main INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liush); groups with view permissions: Set(); users  with modify permissions: Set(liush); groups with modify permissions: Set()
17/09/19 08:28:26.254 main INFO Utils: Successfully started service 'sparkDriver' on port 50919.
17/09/19 08:28:26.400 main INFO SparkEnv: Registering MapOutputTracker
17/09/19 08:28:26.583 main INFO SparkEnv: Registering BlockManagerMaster
17/09/19 08:28:26.650 main INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 08:28:26.651 main INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 08:28:26.680 main INFO DiskBlockManager: Created local directory at /Users/apple/Documents/idea/workspace/spark/external/kinesis-asl/target/tmp/blockmgr-026f6114-8cde-49c5-9265-caf271bdf411
17/09/19 08:28:26.816 main INFO MemoryStore: MemoryStore started with capacity 1638.6 MB
17/09/19 08:28:27.130 main INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 08:28:27.894 main INFO Executor: Starting executor ID driver on host localhost
17/09/19 08:28:28.165 main INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50920.
17/09/19 08:28:28.166 main INFO NettyBlockTransferService: Server created on 192.168.100.237:50920
17/09/19 08:28:28.171 main INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 08:28:28.174 main INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.100.237, 50920, None)
17/09/19 08:28:28.179 dispatcher-event-loop-0 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.100.237:50920 with 1638.6 MB RAM, BlockManagerId(driver, 192.168.100.237, 50920, None)
17/09/19 08:28:28.195 main INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.100.237, 50920, None)
17/09/19 08:28:28.196 main INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.100.237, 50920, None)
17/09/19 08:28:34.770 main WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:28:34.801 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/19 08:28:35.001 main INFO MemoryStore: MemoryStore cleared
17/09/19 08:28:35.003 main INFO BlockManager: BlockManager stopped
17/09/19 08:28:35.058 main INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/19 08:28:35.065 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/19 08:28:35.072 main INFO SparkContext: Successfully stopped SparkContext
17/09/19 08:28:35.080 main WARN StreamingContext: StreamingContext has already been stopped
17/09/19 08:28:35.080 main INFO SparkContext: SparkContext already stopped.
17/09/19 08:28:35.104 main INFO SparkContext: Running Spark version 2.3.0-SNAPSHOT
17/09/19 08:28:35.108 main INFO SparkContext: Submitted application: test
17/09/19 08:28:35.197 main INFO SecurityManager: Changing view acls to: liush
17/09/19 08:28:35.198 main INFO SecurityManager: Changing modify acls to: liush
17/09/19 08:28:35.199 main INFO SecurityManager: Changing view acls groups to: 
17/09/19 08:28:35.199 main INFO SecurityManager: Changing modify acls groups to: 
17/09/19 08:28:35.199 main INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liush); groups with view permissions: Set(); users  with modify permissions: Set(liush); groups with modify permissions: Set()
17/09/19 08:28:35.207 main INFO Utils: Successfully started service 'sparkDriver' on port 50924.
17/09/19 08:28:35.215 main INFO SparkEnv: Registering MapOutputTracker
17/09/19 08:28:35.217 main INFO SparkEnv: Registering BlockManagerMaster
17/09/19 08:28:35.217 main INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 08:28:35.218 main INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 08:28:35.231 main INFO DiskBlockManager: Created local directory at /Users/apple/Documents/idea/workspace/spark/external/kinesis-asl/target/tmp/blockmgr-2bb379cf-5952-48e4-9784-482c4b7d2032
17/09/19 08:28:35.273 main INFO MemoryStore: MemoryStore started with capacity 1638.6 MB
17/09/19 08:28:35.275 main INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 08:28:35.417 main INFO Executor: Starting executor ID driver on host localhost
17/09/19 08:28:35.422 main INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50925.
17/09/19 08:28:35.423 main INFO NettyBlockTransferService: Server created on 192.168.100.237:50925
17/09/19 08:28:35.423 main INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 08:28:35.423 main INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.100.237, 50925, None)
17/09/19 08:28:35.424 dispatcher-event-loop-0 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.100.237:50925 with 1638.6 MB RAM, BlockManagerId(driver, 192.168.100.237, 50925, None)
17/09/19 08:28:35.424 main INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.100.237, 50925, None)
17/09/19 08:28:35.424 main INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.100.237, 50925, None)
17/09/19 08:28:36.034 main WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:28:36.049 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/19 08:28:36.051 main INFO MemoryStore: MemoryStore cleared
17/09/19 08:28:36.051 main INFO BlockManager: BlockManager stopped
17/09/19 08:28:36.052 main INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/19 08:28:36.052 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/19 08:28:36.054 main INFO SparkContext: Successfully stopped SparkContext
17/09/19 08:28:36.054 main WARN StreamingContext: StreamingContext has already been stopped
17/09/19 08:28:36.054 main INFO SparkContext: SparkContext already stopped.
17/09/19 08:28:36.056 main INFO SparkContext: Running Spark version 2.3.0-SNAPSHOT
17/09/19 08:28:36.057 main INFO SparkContext: Submitted application: test
17/09/19 08:28:36.059 main INFO SecurityManager: Changing view acls to: liush
17/09/19 08:28:36.059 main INFO SecurityManager: Changing modify acls to: liush
17/09/19 08:28:36.059 main INFO SecurityManager: Changing view acls groups to: 
17/09/19 08:28:36.059 main INFO SecurityManager: Changing modify acls groups to: 
17/09/19 08:28:36.059 main INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liush); groups with view permissions: Set(); users  with modify permissions: Set(liush); groups with modify permissions: Set()
17/09/19 08:28:36.064 main INFO Utils: Successfully started service 'sparkDriver' on port 50927.
17/09/19 08:28:36.078 main INFO SparkEnv: Registering MapOutputTracker
17/09/19 08:28:36.080 main INFO SparkEnv: Registering BlockManagerMaster
17/09/19 08:28:36.080 main INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 08:28:36.080 main INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 08:28:36.082 main INFO DiskBlockManager: Created local directory at /Users/apple/Documents/idea/workspace/spark/external/kinesis-asl/target/tmp/blockmgr-d71f3e2a-52c1-4ddb-b6af-f8e0733a20ec
17/09/19 08:28:36.083 main INFO MemoryStore: MemoryStore started with capacity 1638.6 MB
17/09/19 08:28:36.085 main INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 08:28:36.231 main INFO Executor: Starting executor ID driver on host localhost
17/09/19 08:28:36.237 main INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50928.
17/09/19 08:28:36.237 main INFO NettyBlockTransferService: Server created on 192.168.100.237:50928
17/09/19 08:28:36.237 main INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 08:28:36.237 main INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.100.237, 50928, None)
17/09/19 08:28:36.238 dispatcher-event-loop-0 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.100.237:50928 with 1638.6 MB RAM, BlockManagerId(driver, 192.168.100.237, 50928, None)
17/09/19 08:28:36.238 main INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.100.237, 50928, None)
17/09/19 08:28:36.238 main INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.100.237, 50928, None)
17/09/19 08:28:36.397 main WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:28:36.415 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/19 08:28:36.417 main INFO MemoryStore: MemoryStore cleared
17/09/19 08:28:36.417 main INFO BlockManager: BlockManager stopped
17/09/19 08:28:36.418 main INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/19 08:28:36.418 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/19 08:28:36.421 main INFO SparkContext: Successfully stopped SparkContext
17/09/19 08:28:36.421 main WARN StreamingContext: StreamingContext has already been stopped
17/09/19 08:28:36.421 main INFO SparkContext: SparkContext already stopped.
17/09/19 08:28:36.424 main INFO SparkContext: Running Spark version 2.3.0-SNAPSHOT
17/09/19 08:28:36.425 main INFO SparkContext: Submitted application: test
17/09/19 08:28:36.428 main INFO SecurityManager: Changing view acls to: liush
17/09/19 08:28:36.428 main INFO SecurityManager: Changing modify acls to: liush
17/09/19 08:28:36.428 main INFO SecurityManager: Changing view acls groups to: 
17/09/19 08:28:36.429 main INFO SecurityManager: Changing modify acls groups to: 
17/09/19 08:28:36.429 main INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liush); groups with view permissions: Set(); users  with modify permissions: Set(liush); groups with modify permissions: Set()
17/09/19 08:28:36.444 main INFO Utils: Successfully started service 'sparkDriver' on port 50929.
17/09/19 08:28:36.449 main INFO SparkEnv: Registering MapOutputTracker
17/09/19 08:28:36.451 main INFO SparkEnv: Registering BlockManagerMaster
17/09/19 08:28:36.451 main INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 08:28:36.451 main INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 08:28:36.452 main INFO DiskBlockManager: Created local directory at /Users/apple/Documents/idea/workspace/spark/external/kinesis-asl/target/tmp/blockmgr-9f38e0a7-bc7f-48b6-a372-55e992cdbf90
17/09/19 08:28:36.453 main INFO MemoryStore: MemoryStore started with capacity 1638.6 MB
17/09/19 08:28:36.455 main INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 08:28:36.736 main INFO Executor: Starting executor ID driver on host localhost
17/09/19 08:28:36.744 main INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50930.
17/09/19 08:28:36.744 main INFO NettyBlockTransferService: Server created on 192.168.100.237:50930
17/09/19 08:28:36.744 main INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 08:28:36.744 main INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.100.237, 50930, None)
17/09/19 08:28:36.745 dispatcher-event-loop-0 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.100.237:50930 with 1638.6 MB RAM, BlockManagerId(driver, 192.168.100.237, 50930, None)
17/09/19 08:28:36.745 main INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.100.237, 50930, None)
17/09/19 08:28:36.746 main INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.100.237, 50930, None)
17/09/19 08:28:36.762 main WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:28:36.848 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/19 08:28:36.867 main INFO MemoryStore: MemoryStore cleared
17/09/19 08:28:36.867 main INFO BlockManager: BlockManager stopped
17/09/19 08:28:36.867 main INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/19 08:28:36.868 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/19 08:28:36.874 main INFO SparkContext: Successfully stopped SparkContext
17/09/19 08:28:36.875 main WARN StreamingContext: StreamingContext has already been stopped
17/09/19 08:28:36.875 main INFO SparkContext: SparkContext already stopped.
17/09/19 08:28:36.879 main INFO SparkContext: Running Spark version 2.3.0-SNAPSHOT
17/09/19 08:28:36.880 main INFO SparkContext: Submitted application: test
17/09/19 08:28:36.881 main INFO SecurityManager: Changing view acls to: liush
17/09/19 08:28:36.881 main INFO SecurityManager: Changing modify acls to: liush
17/09/19 08:28:36.881 main INFO SecurityManager: Changing view acls groups to: 
17/09/19 08:28:36.881 main INFO SecurityManager: Changing modify acls groups to: 
17/09/19 08:28:36.881 main INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liush); groups with view permissions: Set(); users  with modify permissions: Set(liush); groups with modify permissions: Set()
17/09/19 08:28:36.885 main INFO Utils: Successfully started service 'sparkDriver' on port 50931.
17/09/19 08:28:36.948 main INFO SparkEnv: Registering MapOutputTracker
17/09/19 08:28:36.949 main INFO SparkEnv: Registering BlockManagerMaster
17/09/19 08:28:36.950 main INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 08:28:36.950 main INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 08:28:36.953 main INFO DiskBlockManager: Created local directory at /Users/apple/Documents/idea/workspace/spark/external/kinesis-asl/target/tmp/blockmgr-86c2a4d3-fb68-464c-8a3f-33387ba52406
17/09/19 08:28:36.954 main INFO MemoryStore: MemoryStore started with capacity 1638.6 MB
17/09/19 08:28:36.965 main INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 08:28:37.083 main INFO Executor: Starting executor ID driver on host localhost
17/09/19 08:28:37.088 main INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50932.
17/09/19 08:28:37.088 main INFO NettyBlockTransferService: Server created on 192.168.100.237:50932
17/09/19 08:28:37.089 main INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 08:28:37.089 main INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.100.237, 50932, None)
17/09/19 08:28:37.090 dispatcher-event-loop-0 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.100.237:50932 with 1638.6 MB RAM, BlockManagerId(driver, 192.168.100.237, 50932, None)
17/09/19 08:28:37.090 main INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.100.237, 50932, None)
17/09/19 08:28:37.091 main INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.100.237, 50932, None)
17/09/19 08:28:37.139 main WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:28:37.307 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/19 08:28:37.310 main INFO MemoryStore: MemoryStore cleared
17/09/19 08:28:37.310 main INFO BlockManager: BlockManager stopped
17/09/19 08:28:37.310 main INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/19 08:28:37.311 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/19 08:28:37.318 main INFO SparkContext: Successfully stopped SparkContext
17/09/19 08:28:37.319 main WARN StreamingContext: StreamingContext has already been stopped
17/09/19 08:28:37.319 main INFO SparkContext: SparkContext already stopped.
17/09/19 08:28:37.328 main INFO SparkContext: Running Spark version 2.3.0-SNAPSHOT
17/09/19 08:28:37.329 main INFO SparkContext: Submitted application: test
17/09/19 08:28:37.331 main INFO SecurityManager: Changing view acls to: liush
17/09/19 08:28:37.331 main INFO SecurityManager: Changing modify acls to: liush
17/09/19 08:28:37.331 main INFO SecurityManager: Changing view acls groups to: 
17/09/19 08:28:37.331 main INFO SecurityManager: Changing modify acls groups to: 
17/09/19 08:28:37.331 main INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liush); groups with view permissions: Set(); users  with modify permissions: Set(liush); groups with modify permissions: Set()
17/09/19 08:28:37.340 main INFO Utils: Successfully started service 'sparkDriver' on port 50933.
17/09/19 08:28:37.344 main INFO SparkEnv: Registering MapOutputTracker
17/09/19 08:28:37.345 main INFO SparkEnv: Registering BlockManagerMaster
17/09/19 08:28:37.346 main INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 08:28:37.346 main INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 08:28:37.347 main INFO DiskBlockManager: Created local directory at /Users/apple/Documents/idea/workspace/spark/external/kinesis-asl/target/tmp/blockmgr-2bc20256-e6ae-4abf-b164-a3ff4165b9de
17/09/19 08:28:37.348 main INFO MemoryStore: MemoryStore started with capacity 1638.6 MB
17/09/19 08:28:37.352 main INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 08:28:37.595 main INFO Executor: Starting executor ID driver on host localhost
17/09/19 08:28:37.599 main INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50935.
17/09/19 08:28:37.599 main INFO NettyBlockTransferService: Server created on 192.168.100.237:50935
17/09/19 08:28:37.599 main INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 08:28:37.599 main INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.100.237, 50935, None)
17/09/19 08:28:37.614 dispatcher-event-loop-0 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.100.237:50935 with 1638.6 MB RAM, BlockManagerId(driver, 192.168.100.237, 50935, None)
17/09/19 08:28:37.621 main INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.100.237, 50935, None)
17/09/19 08:28:37.621 main INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.100.237, 50935, None)
17/09/19 08:28:37.708 main WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:28:37.711 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/19 08:28:37.715 main INFO MemoryStore: MemoryStore cleared
17/09/19 08:28:37.715 main INFO BlockManager: BlockManager stopped
17/09/19 08:28:37.715 main INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/19 08:28:37.715 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/19 08:28:37.717 main INFO SparkContext: Successfully stopped SparkContext
17/09/19 08:28:37.717 main WARN StreamingContext: StreamingContext has already been stopped
17/09/19 08:28:37.717 main INFO SparkContext: SparkContext already stopped.
17/09/19 08:28:37.726 Thread-1 INFO ShutdownHookManager: Shutdown hook called
17/09/19 08:28:37.727 Thread-1 INFO ShutdownHookManager: Deleting directory /Users/apple/Documents/idea/workspace/spark/external/kinesis-asl/target/tmp/spark-9cac1bc2-106f-4130-a46f-ced244df68f1
17/09/19 08:28:46.460 ScalaTest-main INFO SparkContext: Running Spark version 2.3.0-SNAPSHOT
17/09/19 08:28:50.217 ScalaTest-main WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/19 08:28:52.302 ScalaTest-main INFO SparkContext: Submitted application: KinesisInputDStreamBuilderSuite
17/09/19 08:28:52.801 ScalaTest-main INFO SecurityManager: Changing view acls to: liush
17/09/19 08:28:52.803 ScalaTest-main INFO SecurityManager: Changing modify acls to: liush
17/09/19 08:28:52.862 ScalaTest-main INFO SecurityManager: Changing view acls groups to: 
17/09/19 08:28:52.866 ScalaTest-main INFO SecurityManager: Changing modify acls groups to: 
17/09/19 08:28:52.867 ScalaTest-main INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liush); groups with view permissions: Set(); users  with modify permissions: Set(liush); groups with modify permissions: Set()
17/09/19 08:28:55.267 ScalaTest-main INFO Utils: Successfully started service 'sparkDriver' on port 50947.
17/09/19 08:28:55.461 ScalaTest-main INFO SparkEnv: Registering MapOutputTracker
17/09/19 08:28:55.669 ScalaTest-main INFO SparkEnv: Registering BlockManagerMaster
17/09/19 08:28:55.680 ScalaTest-main INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 08:28:55.686 ScalaTest-main INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 08:28:55.827 ScalaTest-main INFO DiskBlockManager: Created local directory at /Users/apple/Documents/idea/workspace/spark/external/kinesis-asl/target/tmp/blockmgr-20ef6c06-cd2b-4e9b-ae4f-fa6623f1df27
17/09/19 08:28:55.983 ScalaTest-main INFO MemoryStore: MemoryStore started with capacity 1638.6 MB
17/09/19 08:28:56.408 ScalaTest-main INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 08:28:56.983 ScalaTest-main INFO Executor: Starting executor ID driver on host localhost
17/09/19 08:28:57.209 ScalaTest-main INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50948.
17/09/19 08:28:57.210 ScalaTest-main INFO NettyBlockTransferService: Server created on 192.168.100.237:50948
17/09/19 08:28:57.211 ScalaTest-main INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 08:28:57.215 ScalaTest-main INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.100.237, 50948, None)
17/09/19 08:28:57.229 dispatcher-event-loop-0 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.100.237:50948 with 1638.6 MB RAM, BlockManagerId(driver, 192.168.100.237, 50948, None)
17/09/19 08:28:57.234 ScalaTest-main INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.100.237, 50948, None)
17/09/19 08:28:57.235 ScalaTest-main INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.100.237, 50948, None)
17/09/19 08:29:01.467 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: Using manual clock
17/09/19 08:29:01.605 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisInputDStreamBuilderSuite: 'should raise an exception if the StreamingContext is missing' =====

17/09/19 08:29:01.615 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisInputDStreamBuilderSuite: 'should raise an exception if the StreamingContext is missing' =====

17/09/19 08:29:01.655 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: Using manual clock
17/09/19 08:29:01.657 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisInputDStreamBuilderSuite: 'should raise an exception if the stream name is missing' =====

17/09/19 08:29:01.664 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisInputDStreamBuilderSuite: 'should raise an exception if the stream name is missing' =====

17/09/19 08:29:01.665 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: Using manual clock
17/09/19 08:29:01.665 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisInputDStreamBuilderSuite: 'should raise an exception if the checkpoint app name is missing' =====

17/09/19 08:29:01.666 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisInputDStreamBuilderSuite: 'should raise an exception if the checkpoint app name is missing' =====

17/09/19 08:29:01.667 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: Using manual clock
17/09/19 08:29:01.669 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisInputDStreamBuilderSuite: 'should propagate required values to KinesisInputDStream' =====

17/09/19 08:29:03.372 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisInputDStreamBuilderSuite: 'should propagate required values to KinesisInputDStream' =====

17/09/19 08:29:03.379 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: Using manual clock
17/09/19 08:29:03.380 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisInputDStreamBuilderSuite: 'should propagate default values to KinesisInputDStream' =====

17/09/19 08:29:03.399 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisInputDStreamBuilderSuite: 'should propagate default values to KinesisInputDStream' =====

17/09/19 08:29:03.403 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: Using manual clock
17/09/19 08:29:03.404 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisInputDStreamBuilderSuite: 'should propagate custom non-auth values to KinesisInputDStream' =====

17/09/19 08:29:04.437 ScalaTest-main-running-KinesisInputDStreamBuilderSuite INFO KinesisInputDStreamBuilderSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisInputDStreamBuilderSuite: 'should propagate custom non-auth values to KinesisInputDStream' =====

17/09/19 08:29:04.458 ScalaTest-main-running-DiscoverySuite WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:29:04.615 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/19 08:29:04.731 ScalaTest-main-running-DiscoverySuite INFO MemoryStore: MemoryStore cleared
17/09/19 08:29:04.764 ScalaTest-main-running-DiscoverySuite INFO BlockManager: BlockManager stopped
17/09/19 08:29:04.775 ScalaTest-main-running-DiscoverySuite INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/19 08:29:04.780 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/19 08:29:04.783 ScalaTest-main-running-DiscoverySuite INFO SparkContext: Successfully stopped SparkContext
17/09/19 08:29:05.170 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'process records including store and set checkpointer' =====

17/09/19 08:29:05.371 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisRecordProcessor: Initialized workerId dummyWorkerId with shardId dummyShardId
17/09/19 08:29:05.422 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'process records including store and set checkpointer' =====

17/09/19 08:29:05.450 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'split into multiple processes if a limitation is set' =====

17/09/19 08:29:05.531 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisRecordProcessor: Initialized workerId dummyWorkerId with shardId dummyShardId
17/09/19 08:29:05.553 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'split into multiple processes if a limitation is set' =====

17/09/19 08:29:05.609 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'shouldn't store and update checkpointer when receiver is stopped' =====

17/09/19 08:29:05.610 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisRecordProcessor: Stopped:  KinesisReceiver has stopped for workerId dummyWorkerId and shardId null.  No more records will be processed.
17/09/19 08:29:05.628 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'shouldn't store and update checkpointer when receiver is stopped' =====

17/09/19 08:29:05.742 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'shouldn't update checkpointer when exception occurs during store' =====

17/09/19 08:29:05.755 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisRecordProcessor: Initialized workerId dummyWorkerId with shardId dummyShardId
17/09/19 08:29:05.768 ScalaTest-main-running-KinesisReceiverSuite ERROR KinesisRecordProcessor: Exception:  WorkerId dummyWorkerId encountered and exception while storing  or checkpointing a batch for workerId dummyWorkerId and shardId dummyShardId.
java.lang.RuntimeException
	at org.apache.spark.streaming.kinesis.KinesisRecordProcessor$$anonfun$processRecords$1.apply$mcVI$sp(KinesisRecordProcessor.scala:79)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.streaming.kinesis.KinesisRecordProcessor.processRecords(KinesisRecordProcessor.scala:77)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$4$$anonfun$apply$mcV$sp$1.apply$mcV$sp(KinesisReceiverSuite.scala:113)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$4$$anonfun$apply$mcV$sp$1.apply(KinesisReceiverSuite.scala:110)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$4$$anonfun$apply$mcV$sp$1.apply(KinesisReceiverSuite.scala:110)
	at org.scalatest.Assertions$class.intercept(Assertions.scala:805)
	at org.scalatest.FunSuite.intercept(FunSuite.scala:1560)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$4.apply$mcV$sp(KinesisReceiverSuite.scala:110)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$4.apply(KinesisReceiverSuite.scala:103)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$4.apply(KinesisReceiverSuite.scala:103)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:68)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:31)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:213)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:210)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$run(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.run(KinesisReceiverSuite.scala:38)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1210)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1257)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1255)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1255)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:30)
	at org.scalatest.Suite$class.run(Suite.scala:1144)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:30)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:45)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1340)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1334)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1334)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1011)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1010)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1500)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1010)
	at org.scalatest.tools.Runner$.main(Runner.scala:827)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/09/19 08:29:05.775 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'shouldn't update checkpointer when exception occurs during store' =====

17/09/19 08:29:05.839 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'shutdown should checkpoint if the reason is TERMINATE' =====

17/09/19 08:29:05.840 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisRecordProcessor: Initialized workerId dummyWorkerId with shardId dummyShardId
17/09/19 08:29:05.852 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisRecordProcessor: Shutdown:  Shutting down workerId dummyWorkerId with reason TERMINATE
17/09/19 08:29:05.852 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'shutdown should checkpoint if the reason is TERMINATE' =====

17/09/19 08:29:05.869 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'shutdown should not checkpoint if the reason is something other than TERMINATE' =====

17/09/19 08:29:05.869 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisRecordProcessor: Initialized workerId dummyWorkerId with shardId dummyShardId
17/09/19 08:29:05.869 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisRecordProcessor: Shutdown:  Shutting down workerId dummyWorkerId with reason ZOMBIE
17/09/19 08:29:05.869 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisRecordProcessor: Shutdown:  Shutting down workerId dummyWorkerId with reason null
17/09/19 08:29:05.870 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'shutdown should not checkpoint if the reason is something other than TERMINATE' =====

17/09/19 08:29:05.883 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry success on first attempt' =====

17/09/19 08:29:05.885 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry success on first attempt' =====

17/09/19 08:29:05.896 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry success on second attempt after a Kinesis throttling exception' =====

17/09/19 08:29:05.979 ScalaTest-main-running-KinesisReceiverSuite ERROR KinesisRecordProcessor: Retryable Exception:  Random backOffMillis=76
com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException: error message
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$9$$anonfun$10.apply$mcZ$sp(KinesisReceiverSuite.scala:160)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$9$$anonfun$10.apply(KinesisReceiverSuite.scala:160)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$9$$anonfun$10.apply(KinesisReceiverSuite.scala:160)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.kinesis.KinesisRecordProcessor$.retryRandom(KinesisRecordProcessor.scala:158)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$9.apply$mcZ$sp(KinesisReceiverSuite.scala:160)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$9.apply(KinesisReceiverSuite.scala:154)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$9.apply(KinesisReceiverSuite.scala:154)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:68)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:31)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:213)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:210)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$run(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.run(KinesisReceiverSuite.scala:38)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1210)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1257)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1255)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1255)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:30)
	at org.scalatest.Suite$class.run(Suite.scala:1144)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:30)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:45)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1340)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1334)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1334)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1011)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1010)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1500)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1010)
	at org.scalatest.tools.Runner$.main(Runner.scala:827)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/09/19 08:29:05.980 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry success on second attempt after a Kinesis throttling exception' =====

17/09/19 08:29:05.994 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry success on second attempt after a Kinesis dependency exception' =====

17/09/19 08:29:06.094 ScalaTest-main-running-KinesisReceiverSuite ERROR KinesisRecordProcessor: Retryable Exception:  Random backOffMillis=94
com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException: error message
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$11$$anonfun$12.apply$mcZ$sp(KinesisReceiverSuite.scala:172)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$11$$anonfun$12.apply(KinesisReceiverSuite.scala:172)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$11$$anonfun$12.apply(KinesisReceiverSuite.scala:172)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.kinesis.KinesisRecordProcessor$.retryRandom(KinesisRecordProcessor.scala:158)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$11.apply$mcZ$sp(KinesisReceiverSuite.scala:172)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$11.apply(KinesisReceiverSuite.scala:166)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$11.apply(KinesisReceiverSuite.scala:166)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:68)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:31)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:213)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:210)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$run(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.run(KinesisReceiverSuite.scala:38)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1210)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1257)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1255)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1255)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:30)
	at org.scalatest.Suite$class.run(Suite.scala:1144)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:30)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:45)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1340)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1334)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1334)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1011)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1010)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1500)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1010)
	at org.scalatest.tools.Runner$.main(Runner.scala:827)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/09/19 08:29:06.099 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry success on second attempt after a Kinesis dependency exception' =====

17/09/19 08:29:06.116 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry failed after a shutdown exception' =====

17/09/19 08:29:06.117 ScalaTest-main-running-KinesisReceiverSuite ERROR KinesisRecordProcessor: ShutdownException:  Caught shutdown exception, skipping checkpoint.
com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException: error message
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$13$$anonfun$apply$mcV$sp$2$$anonfun$apply$mcV$sp$3.apply$mcV$sp(KinesisReceiverSuite.scala:182)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$13$$anonfun$apply$mcV$sp$2$$anonfun$apply$mcV$sp$3.apply(KinesisReceiverSuite.scala:182)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$13$$anonfun$apply$mcV$sp$2$$anonfun$apply$mcV$sp$3.apply(KinesisReceiverSuite.scala:182)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.kinesis.KinesisRecordProcessor$.retryRandom(KinesisRecordProcessor.scala:158)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$13$$anonfun$apply$mcV$sp$2.apply$mcV$sp(KinesisReceiverSuite.scala:182)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$13$$anonfun$apply$mcV$sp$2.apply(KinesisReceiverSuite.scala:182)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$13$$anonfun$apply$mcV$sp$2.apply(KinesisReceiverSuite.scala:182)
	at org.scalatest.Assertions$class.intercept(Assertions.scala:805)
	at org.scalatest.FunSuite.intercept(FunSuite.scala:1560)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$13.apply$mcV$sp(KinesisReceiverSuite.scala:181)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$13.apply(KinesisReceiverSuite.scala:178)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$13.apply(KinesisReceiverSuite.scala:178)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:68)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:31)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:213)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:210)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$run(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.run(KinesisReceiverSuite.scala:38)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1210)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1257)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1255)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1255)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:30)
	at org.scalatest.Suite$class.run(Suite.scala:1144)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:30)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:45)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1340)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1334)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1334)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1011)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1010)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1500)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1010)
	at org.scalatest.tools.Runner$.main(Runner.scala:827)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/09/19 08:29:06.118 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry failed after a shutdown exception' =====

17/09/19 08:29:06.142 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry failed after an invalid state exception' =====

17/09/19 08:29:06.143 ScalaTest-main-running-KinesisReceiverSuite ERROR KinesisRecordProcessor: InvalidStateException:  Cannot save checkpoint to the DynamoDB table used by the Amazon Kinesis Client Library.  Table likely doesn't exist.
com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException: error message
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$14$$anonfun$apply$mcV$sp$4$$anonfun$apply$mcV$sp$5.apply$mcV$sp(KinesisReceiverSuite.scala:192)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$14$$anonfun$apply$mcV$sp$4$$anonfun$apply$mcV$sp$5.apply(KinesisReceiverSuite.scala:192)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$14$$anonfun$apply$mcV$sp$4$$anonfun$apply$mcV$sp$5.apply(KinesisReceiverSuite.scala:192)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.kinesis.KinesisRecordProcessor$.retryRandom(KinesisRecordProcessor.scala:158)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$14$$anonfun$apply$mcV$sp$4.apply$mcV$sp(KinesisReceiverSuite.scala:192)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$14$$anonfun$apply$mcV$sp$4.apply(KinesisReceiverSuite.scala:192)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$14$$anonfun$apply$mcV$sp$4.apply(KinesisReceiverSuite.scala:192)
	at org.scalatest.Assertions$class.intercept(Assertions.scala:805)
	at org.scalatest.FunSuite.intercept(FunSuite.scala:1560)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$14.apply$mcV$sp(KinesisReceiverSuite.scala:191)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$14.apply(KinesisReceiverSuite.scala:188)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$14.apply(KinesisReceiverSuite.scala:188)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:68)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:31)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:213)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:210)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$run(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.run(KinesisReceiverSuite.scala:38)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1210)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1257)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1255)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1255)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:30)
	at org.scalatest.Suite$class.run(Suite.scala:1144)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:30)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:45)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1340)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1334)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1334)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1011)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1010)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1500)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1010)
	at org.scalatest.tools.Runner$.main(Runner.scala:827)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/09/19 08:29:06.143 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry failed after an invalid state exception' =====

17/09/19 08:29:06.150 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry failed after unexpected exception' =====

17/09/19 08:29:06.151 ScalaTest-main-running-KinesisReceiverSuite ERROR KinesisRecordProcessor: Unexpected, non-retryable exception.
java.lang.RuntimeException: error message
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$15$$anonfun$apply$mcV$sp$6$$anonfun$apply$mcV$sp$7.apply$mcV$sp(KinesisReceiverSuite.scala:202)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$15$$anonfun$apply$mcV$sp$6$$anonfun$apply$mcV$sp$7.apply(KinesisReceiverSuite.scala:202)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$15$$anonfun$apply$mcV$sp$6$$anonfun$apply$mcV$sp$7.apply(KinesisReceiverSuite.scala:202)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.kinesis.KinesisRecordProcessor$.retryRandom(KinesisRecordProcessor.scala:158)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$15$$anonfun$apply$mcV$sp$6.apply$mcV$sp(KinesisReceiverSuite.scala:202)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$15$$anonfun$apply$mcV$sp$6.apply(KinesisReceiverSuite.scala:202)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$15$$anonfun$apply$mcV$sp$6.apply(KinesisReceiverSuite.scala:202)
	at org.scalatest.Assertions$class.intercept(Assertions.scala:805)
	at org.scalatest.FunSuite.intercept(FunSuite.scala:1560)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$15.apply$mcV$sp(KinesisReceiverSuite.scala:201)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$15.apply(KinesisReceiverSuite.scala:198)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$15.apply(KinesisReceiverSuite.scala:198)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:68)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:31)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:213)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:210)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$run(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.run(KinesisReceiverSuite.scala:38)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1210)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1257)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1255)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1255)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:30)
	at org.scalatest.Suite$class.run(Suite.scala:1144)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:30)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:45)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1340)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1334)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1334)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1011)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1010)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1500)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1010)
	at org.scalatest.tools.Runner$.main(Runner.scala:827)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/09/19 08:29:06.152 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry failed after unexpected exception' =====

17/09/19 08:29:06.166 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry failed after exhausting all retries' =====

17/09/19 08:29:06.234 ScalaTest-main-running-KinesisReceiverSuite ERROR KinesisRecordProcessor: Retryable Exception:  Random backOffMillis=59
com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException: error message
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16$$anonfun$17$$anonfun$apply$mcV$sp$8.apply$mcV$sp(KinesisReceiverSuite.scala:215)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16$$anonfun$17$$anonfun$apply$mcV$sp$8.apply(KinesisReceiverSuite.scala:215)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16$$anonfun$17$$anonfun$apply$mcV$sp$8.apply(KinesisReceiverSuite.scala:215)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.kinesis.KinesisRecordProcessor$.retryRandom(KinesisRecordProcessor.scala:158)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16$$anonfun$17.apply$mcV$sp(KinesisReceiverSuite.scala:215)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16$$anonfun$17.apply(KinesisReceiverSuite.scala:215)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16$$anonfun$17.apply(KinesisReceiverSuite.scala:215)
	at org.scalatest.Assertions$class.intercept(Assertions.scala:805)
	at org.scalatest.FunSuite.intercept(FunSuite.scala:1560)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16.apply$mcV$sp(KinesisReceiverSuite.scala:214)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16.apply(KinesisReceiverSuite.scala:208)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16.apply(KinesisReceiverSuite.scala:208)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:68)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:31)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:213)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:210)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$run(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.run(KinesisReceiverSuite.scala:38)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1210)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1257)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1255)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1255)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:30)
	at org.scalatest.Suite$class.run(Suite.scala:1144)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:30)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:45)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1340)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1334)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1334)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1011)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1010)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1500)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1010)
	at org.scalatest.tools.Runner$.main(Runner.scala:827)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/09/19 08:29:06.236 ScalaTest-main-running-KinesisReceiverSuite ERROR KinesisRecordProcessor: Unexpected, non-retryable exception.
com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException: final try error message
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16$$anonfun$17$$anonfun$apply$mcV$sp$8.apply$mcV$sp(KinesisReceiverSuite.scala:215)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16$$anonfun$17$$anonfun$apply$mcV$sp$8.apply(KinesisReceiverSuite.scala:215)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16$$anonfun$17$$anonfun$apply$mcV$sp$8.apply(KinesisReceiverSuite.scala:215)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.kinesis.KinesisRecordProcessor$.retryRandom(KinesisRecordProcessor.scala:158)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16$$anonfun$17.apply$mcV$sp(KinesisReceiverSuite.scala:215)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16$$anonfun$17.apply(KinesisReceiverSuite.scala:215)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16$$anonfun$17.apply(KinesisReceiverSuite.scala:215)
	at org.scalatest.Assertions$class.intercept(Assertions.scala:805)
	at org.scalatest.FunSuite.intercept(FunSuite.scala:1560)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16.apply$mcV$sp(KinesisReceiverSuite.scala:214)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16.apply(KinesisReceiverSuite.scala:208)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite$$anonfun$16.apply(KinesisReceiverSuite.scala:208)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:68)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.runTest(KinesisReceiverSuite.scala:38)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:31)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:213)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:210)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.org$scalatest$BeforeAndAfter$$super$run(KinesisReceiverSuite.scala:38)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at org.apache.spark.streaming.kinesis.KinesisReceiverSuite.run(KinesisReceiverSuite.scala:38)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1210)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1257)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1255)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1255)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:30)
	at org.scalatest.Suite$class.run(Suite.scala:1144)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:30)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:45)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1340)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1334)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1334)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1011)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1010)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1500)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1010)
	at org.scalatest.tools.Runner$.main(Runner.scala:827)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/09/19 08:29:06.259 ScalaTest-main-running-KinesisReceiverSuite INFO KinesisReceiverSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisReceiverSuite: 'retry failed after exhausting all retries' =====

17/09/19 08:29:06.271 ScalaTest-main-running-DiscoverySuite INFO SparkContext: Running Spark version 2.3.0-SNAPSHOT
17/09/19 08:29:06.272 ScalaTest-main-running-DiscoverySuite INFO SparkContext: Submitted application: KinesisStreamSuite
17/09/19 08:29:06.273 ScalaTest-main-running-DiscoverySuite INFO SecurityManager: Changing view acls to: liush
17/09/19 08:29:06.273 ScalaTest-main-running-DiscoverySuite INFO SecurityManager: Changing modify acls to: liush
17/09/19 08:29:06.273 ScalaTest-main-running-DiscoverySuite INFO SecurityManager: Changing view acls groups to: 
17/09/19 08:29:06.274 ScalaTest-main-running-DiscoverySuite INFO SecurityManager: Changing modify acls groups to: 
17/09/19 08:29:06.274 ScalaTest-main-running-DiscoverySuite INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liush); groups with view permissions: Set(); users  with modify permissions: Set(liush); groups with modify permissions: Set()
17/09/19 08:29:06.290 ScalaTest-main-running-DiscoverySuite INFO Utils: Successfully started service 'sparkDriver' on port 50950.
17/09/19 08:29:06.296 ScalaTest-main-running-DiscoverySuite INFO SparkEnv: Registering MapOutputTracker
17/09/19 08:29:06.297 ScalaTest-main-running-DiscoverySuite INFO SparkEnv: Registering BlockManagerMaster
17/09/19 08:29:06.298 ScalaTest-main-running-DiscoverySuite INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 08:29:06.298 ScalaTest-main-running-DiscoverySuite INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 08:29:06.299 ScalaTest-main-running-DiscoverySuite INFO DiskBlockManager: Created local directory at /Users/apple/Documents/idea/workspace/spark/external/kinesis-asl/target/tmp/blockmgr-21ade196-8c87-4930-9b52-9542d3c0d1b2
17/09/19 08:29:06.300 ScalaTest-main-running-DiscoverySuite INFO MemoryStore: MemoryStore started with capacity 1638.6 MB
17/09/19 08:29:06.301 ScalaTest-main-running-DiscoverySuite INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 08:29:06.388 ScalaTest-main-running-DiscoverySuite INFO Executor: Starting executor ID driver on host localhost
17/09/19 08:29:06.394 ScalaTest-main-running-DiscoverySuite INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50951.
17/09/19 08:29:06.394 ScalaTest-main-running-DiscoverySuite INFO NettyBlockTransferService: Server created on 192.168.100.237:50951
17/09/19 08:29:06.394 ScalaTest-main-running-DiscoverySuite INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 08:29:06.394 ScalaTest-main-running-DiscoverySuite INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.100.237, 50951, None)
17/09/19 08:29:06.395 dispatcher-event-loop-2 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.100.237:50951 with 1638.6 MB RAM, BlockManagerId(driver, 192.168.100.237, 50951, None)
17/09/19 08:29:06.395 ScalaTest-main-running-DiscoverySuite INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.100.237, 50951, None)
17/09/19 08:29:06.396 ScalaTest-main-running-DiscoverySuite INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.100.237, 50951, None)
17/09/19 08:29:06.408 ScalaTest-main-running-WithAggregationKinesisStreamSuite INFO WithAggregationKinesisStreamSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.WithAggregationKinesisStreamSuite: 'KinesisUtils API' =====

17/09/19 08:29:06.556 ScalaTest-main-running-WithAggregationKinesisStreamSuite INFO WithAggregationKinesisStreamSuite: 

===== FINISHED o.a.s.streaming.kinesis.WithAggregationKinesisStreamSuite: 'KinesisUtils API' =====

17/09/19 08:29:06.556 ScalaTest-main-running-WithAggregationKinesisStreamSuite WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:29:06.567 ScalaTest-main-running-WithAggregationKinesisStreamSuite INFO WithAggregationKinesisStreamSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.WithAggregationKinesisStreamSuite: 'RDD generation' =====

17/09/19 08:29:06.688 ScalaTest-main-running-WithAggregationKinesisStreamSuite INFO WithAggregationKinesisStreamSuite: 

===== FINISHED o.a.s.streaming.kinesis.WithAggregationKinesisStreamSuite: 'RDD generation' =====

17/09/19 08:29:06.688 ScalaTest-main-running-WithAggregationKinesisStreamSuite WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:29:06.720 ScalaTest-main-running-WithAggregationKinesisStreamSuite INFO WithAggregationKinesisStreamSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.WithAggregationKinesisStreamSuite: 'Kinesis read with custom configurations' =====

17/09/19 08:29:06.725 ScalaTest-main-running-WithAggregationKinesisStreamSuite WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:29:06.725 ScalaTest-main-running-WithAggregationKinesisStreamSuite INFO WithAggregationKinesisStreamSuite: 

===== FINISHED o.a.s.streaming.kinesis.WithAggregationKinesisStreamSuite: 'Kinesis read with custom configurations' =====

17/09/19 08:29:06.726 ScalaTest-main-running-WithAggregationKinesisStreamSuite WARN StreamingContext: StreamingContext has already been stopped
17/09/19 08:29:06.782 dispatcher-event-loop-2 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/19 08:29:06.785 ScalaTest-main-running-DiscoverySuite INFO MemoryStore: MemoryStore cleared
17/09/19 08:29:06.785 ScalaTest-main-running-DiscoverySuite INFO BlockManager: BlockManager stopped
17/09/19 08:29:06.786 ScalaTest-main-running-DiscoverySuite INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/19 08:29:06.786 dispatcher-event-loop-3 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/19 08:29:06.789 ScalaTest-main-running-DiscoverySuite INFO SparkContext: Successfully stopped SparkContext
17/09/19 08:29:06.799 ScalaTest-main-running-KinesisCheckpointerSuite INFO RecurringTimer: Started timer for Kinesis Checkpointer - Worker dummyWorkerId at time 10
17/09/19 08:29:06.799 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: Using manual clock
17/09/19 08:29:06.799 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'checkpoint is not called twice for the same sequence number' =====

17/09/19 08:29:06.811 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'checkpoint is not called twice for the same sequence number' =====

17/09/19 08:29:06.818 ScalaTest-main-running-KinesisCheckpointerSuite INFO RecurringTimer: Started timer for Kinesis Checkpointer - Worker dummyWorkerId at time 10
17/09/19 08:29:06.819 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: Using manual clock
17/09/19 08:29:06.819 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'checkpoint is called after sequence number increases' =====

17/09/19 08:29:06.821 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'checkpoint is called after sequence number increases' =====

17/09/19 08:29:06.831 ScalaTest-main-running-KinesisCheckpointerSuite INFO RecurringTimer: Started timer for Kinesis Checkpointer - Worker dummyWorkerId at time 10
17/09/19 08:29:06.831 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: Using manual clock
17/09/19 08:29:06.832 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'should checkpoint if we have exceeded the checkpoint interval' =====

17/09/19 08:29:06.839 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'should checkpoint if we have exceeded the checkpoint interval' =====

17/09/19 08:29:06.850 ScalaTest-main-running-KinesisCheckpointerSuite INFO RecurringTimer: Started timer for Kinesis Checkpointer - Worker dummyWorkerId at time 10
17/09/19 08:29:06.851 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: Using manual clock
17/09/19 08:29:06.852 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'shouldn't checkpoint if we have not exceeded the checkpoint interval' =====

17/09/19 08:29:06.852 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'shouldn't checkpoint if we have not exceeded the checkpoint interval' =====

17/09/19 08:29:06.943 ScalaTest-main-running-KinesisCheckpointerSuite INFO RecurringTimer: Started timer for Kinesis Checkpointer - Worker dummyWorkerId at time 10
17/09/19 08:29:06.944 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: Using manual clock
17/09/19 08:29:06.947 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'should not checkpoint for the same sequence number' =====

17/09/19 08:29:06.961 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'should not checkpoint for the same sequence number' =====

17/09/19 08:29:06.968 ScalaTest-main-running-KinesisCheckpointerSuite INFO RecurringTimer: Started timer for Kinesis Checkpointer - Worker dummyWorkerId at time 10
17/09/19 08:29:06.969 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: Using manual clock
17/09/19 08:29:06.970 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'removing checkpointer checkpoints one last time' =====

17/09/19 08:29:06.970 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'removing checkpointer checkpoints one last time' =====

17/09/19 08:29:06.977 ScalaTest-main-running-KinesisCheckpointerSuite INFO RecurringTimer: Started timer for Kinesis Checkpointer - Worker dummyWorkerId at time 10
17/09/19 08:29:07.016 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: Using manual clock
17/09/19 08:29:07.016 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'if checkpointing is going on, wait until finished before removing and checkpointing' =====

17/09/19 08:29:07.117 ScalaTest-main-running-KinesisCheckpointerSuite INFO KinesisCheckpointerSuite: 

===== FINISHED o.a.s.streaming.kinesis.KinesisCheckpointerSuite: 'if checkpointing is going on, wait until finished before removing and checkpointing' =====

17/09/19 08:29:07.121 ScalaTest-main-running-SparkAWSCredentialsBuilderSuite INFO SparkAWSCredentialsBuilderSuite: Using manual clock
17/09/19 08:29:07.121 ScalaTest-main-running-SparkAWSCredentialsBuilderSuite INFO SparkAWSCredentialsBuilderSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.SparkAWSCredentialsBuilderSuite: 'should build DefaultCredentials when given no params' =====

17/09/19 08:29:07.122 ScalaTest-main-running-SparkAWSCredentialsBuilderSuite INFO SparkAWSCredentialsBuilderSuite: 

===== FINISHED o.a.s.streaming.kinesis.SparkAWSCredentialsBuilderSuite: 'should build DefaultCredentials when given no params' =====

17/09/19 08:29:07.122 ScalaTest-main-running-SparkAWSCredentialsBuilderSuite INFO SparkAWSCredentialsBuilderSuite: Using manual clock
17/09/19 08:29:07.123 ScalaTest-main-running-SparkAWSCredentialsBuilderSuite INFO SparkAWSCredentialsBuilderSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.SparkAWSCredentialsBuilderSuite: 'should build BasicCredentials' =====

17/09/19 08:29:07.123 ScalaTest-main-running-SparkAWSCredentialsBuilderSuite INFO SparkAWSCredentialsBuilderSuite: 

===== FINISHED o.a.s.streaming.kinesis.SparkAWSCredentialsBuilderSuite: 'should build BasicCredentials' =====

17/09/19 08:29:07.123 ScalaTest-main-running-SparkAWSCredentialsBuilderSuite INFO SparkAWSCredentialsBuilderSuite: Using manual clock
17/09/19 08:29:07.124 ScalaTest-main-running-SparkAWSCredentialsBuilderSuite INFO SparkAWSCredentialsBuilderSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.SparkAWSCredentialsBuilderSuite: 'should build STSCredentials' =====

17/09/19 08:29:07.124 ScalaTest-main-running-SparkAWSCredentialsBuilderSuite INFO SparkAWSCredentialsBuilderSuite: 

===== FINISHED o.a.s.streaming.kinesis.SparkAWSCredentialsBuilderSuite: 'should build STSCredentials' =====

17/09/19 08:29:07.125 ScalaTest-main-running-SparkAWSCredentialsBuilderSuite INFO SparkAWSCredentialsBuilderSuite: Using manual clock
17/09/19 08:29:07.125 ScalaTest-main-running-SparkAWSCredentialsBuilderSuite INFO SparkAWSCredentialsBuilderSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.SparkAWSCredentialsBuilderSuite: 'SparkAWSCredentials classes should be serializable' =====

17/09/19 08:29:07.157 ScalaTest-main-running-SparkAWSCredentialsBuilderSuite INFO SparkAWSCredentialsBuilderSuite: 

===== FINISHED o.a.s.streaming.kinesis.SparkAWSCredentialsBuilderSuite: 'SparkAWSCredentials classes should be serializable' =====

17/09/19 08:29:07.159 ScalaTest-main-running-DiscoverySuite INFO SparkContext: Running Spark version 2.3.0-SNAPSHOT
17/09/19 08:29:07.160 ScalaTest-main-running-DiscoverySuite INFO SparkContext: Submitted application: KinesisStreamSuite
17/09/19 08:29:07.161 ScalaTest-main-running-DiscoverySuite INFO SecurityManager: Changing view acls to: liush
17/09/19 08:29:07.161 ScalaTest-main-running-DiscoverySuite INFO SecurityManager: Changing modify acls to: liush
17/09/19 08:29:07.162 ScalaTest-main-running-DiscoverySuite INFO SecurityManager: Changing view acls groups to: 
17/09/19 08:29:07.163 ScalaTest-main-running-DiscoverySuite INFO SecurityManager: Changing modify acls groups to: 
17/09/19 08:29:07.163 ScalaTest-main-running-DiscoverySuite INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(liush); groups with view permissions: Set(); users  with modify permissions: Set(liush); groups with modify permissions: Set()
17/09/19 08:29:07.175 ScalaTest-main-running-DiscoverySuite INFO Utils: Successfully started service 'sparkDriver' on port 50952.
17/09/19 08:29:07.189 ScalaTest-main-running-DiscoverySuite INFO SparkEnv: Registering MapOutputTracker
17/09/19 08:29:07.190 ScalaTest-main-running-DiscoverySuite INFO SparkEnv: Registering BlockManagerMaster
17/09/19 08:29:07.191 ScalaTest-main-running-DiscoverySuite INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 08:29:07.191 ScalaTest-main-running-DiscoverySuite INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 08:29:07.193 ScalaTest-main-running-DiscoverySuite INFO DiskBlockManager: Created local directory at /Users/apple/Documents/idea/workspace/spark/external/kinesis-asl/target/tmp/blockmgr-b33ddd89-675c-4c8e-b8b3-d2b44f4ce79b
17/09/19 08:29:07.196 ScalaTest-main-running-DiscoverySuite INFO MemoryStore: MemoryStore started with capacity 1638.6 MB
17/09/19 08:29:07.216 ScalaTest-main-running-DiscoverySuite INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 08:29:07.333 ScalaTest-main-running-DiscoverySuite INFO Executor: Starting executor ID driver on host localhost
17/09/19 08:29:07.339 ScalaTest-main-running-DiscoverySuite INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50953.
17/09/19 08:29:07.339 ScalaTest-main-running-DiscoverySuite INFO NettyBlockTransferService: Server created on 192.168.100.237:50953
17/09/19 08:29:07.339 ScalaTest-main-running-DiscoverySuite INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 08:29:07.339 ScalaTest-main-running-DiscoverySuite INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.100.237, 50953, None)
17/09/19 08:29:07.340 dispatcher-event-loop-2 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.100.237:50953 with 1638.6 MB RAM, BlockManagerId(driver, 192.168.100.237, 50953, None)
17/09/19 08:29:07.340 ScalaTest-main-running-DiscoverySuite INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.100.237, 50953, None)
17/09/19 08:29:07.340 ScalaTest-main-running-DiscoverySuite INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.100.237, 50953, None)
17/09/19 08:29:07.346 ScalaTest-main-running-WithoutAggregationKinesisStreamSuite INFO WithoutAggregationKinesisStreamSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.WithoutAggregationKinesisStreamSuite: 'KinesisUtils API' =====

17/09/19 08:29:07.349 ScalaTest-main-running-WithoutAggregationKinesisStreamSuite INFO WithoutAggregationKinesisStreamSuite: 

===== FINISHED o.a.s.streaming.kinesis.WithoutAggregationKinesisStreamSuite: 'KinesisUtils API' =====

17/09/19 08:29:07.350 ScalaTest-main-running-WithoutAggregationKinesisStreamSuite WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:29:07.351 ScalaTest-main-running-WithoutAggregationKinesisStreamSuite INFO WithoutAggregationKinesisStreamSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.WithoutAggregationKinesisStreamSuite: 'RDD generation' =====

17/09/19 08:29:07.398 ScalaTest-main-running-WithoutAggregationKinesisStreamSuite INFO WithoutAggregationKinesisStreamSuite: 

===== FINISHED o.a.s.streaming.kinesis.WithoutAggregationKinesisStreamSuite: 'RDD generation' =====

17/09/19 08:29:07.398 ScalaTest-main-running-WithoutAggregationKinesisStreamSuite WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:29:07.407 ScalaTest-main-running-WithoutAggregationKinesisStreamSuite INFO WithoutAggregationKinesisStreamSuite: 

===== TEST OUTPUT FOR o.a.s.streaming.kinesis.WithoutAggregationKinesisStreamSuite: 'Kinesis read with custom configurations' =====

17/09/19 08:29:07.415 ScalaTest-main-running-WithoutAggregationKinesisStreamSuite WARN StreamingContext: StreamingContext has not been started yet
17/09/19 08:29:07.415 ScalaTest-main-running-WithoutAggregationKinesisStreamSuite INFO WithoutAggregationKinesisStreamSuite: 

===== FINISHED o.a.s.streaming.kinesis.WithoutAggregationKinesisStreamSuite: 'Kinesis read with custom configurations' =====

17/09/19 08:29:07.416 ScalaTest-main-running-WithoutAggregationKinesisStreamSuite WARN StreamingContext: StreamingContext has already been stopped
17/09/19 08:29:07.429 dispatcher-event-loop-2 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/19 08:29:07.432 ScalaTest-main-running-DiscoverySuite INFO MemoryStore: MemoryStore cleared
17/09/19 08:29:07.432 ScalaTest-main-running-DiscoverySuite INFO BlockManager: BlockManager stopped
17/09/19 08:29:07.432 ScalaTest-main-running-DiscoverySuite INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/19 08:29:07.432 dispatcher-event-loop-3 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/19 08:29:07.435 ScalaTest-main-running-DiscoverySuite INFO SparkContext: Successfully stopped SparkContext
17/09/19 08:29:07.472 Thread-1 INFO ShutdownHookManager: Shutdown hook called
17/09/19 08:29:07.473 Thread-1 INFO ShutdownHookManager: Deleting directory /Users/apple/Documents/idea/workspace/spark/external/kinesis-asl/target/tmp/spark-25eab128-016b-41ad-aad9-68ac2f3aebc5
